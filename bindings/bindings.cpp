#include <pybind11/pybind11.h>
#include <pybind11/stl.h>
#include <pybind11/numpy.h>
#include <armadillo>
#include "linearregression.h"
#include "normalequation.h"
#include "batchgradientdescent.h"

// CODE IN THIS FILE WAS AUTO-GENERATED BY GPT-5 mini
namespace py = pybind11;


py::array_t<double> arma_mat_to_numpy(const arma::mat& mat) {
    // Copy data because Armadillo is column-major and NumPy is row-major
    auto result = py::array_t<double>({mat.n_rows, mat.n_cols});
    auto buf = result.mutable_unchecked<2>();
    for (arma::uword i = 0; i < mat.n_rows; ++i)
        for (arma::uword j = 0; j < mat.n_cols; ++j)
            buf(i, j) = mat(i, j);
    return result;
}


py::array_t<double> arma_vec_to_numpy(const arma::vec& vec) {
    auto result = py::array_t<double>(vec.n_elem);
    auto buf = result.mutable_unchecked<1>();
    for (arma::uword i = 0; i < vec.n_elem; ++i)
        buf(i) = vec(i);
    return result;
}

arma::mat foo(arma::mat x)
{
    return x;
}

arma::mat numpy_to_arma_mat(const py::array_t<double>& array) {
    py::buffer_info buf = array.request();
    if (buf.ndim != 2)
        throw std::runtime_error("NumPy array must be 2D for arma::mat");

    arma::mat mat(buf.shape[0], buf.shape[1]);
    double* ptr = static_cast<double*>(buf.ptr);

    // Copy data row-major → column-major
    for (ssize_t i = 0; i < buf.shape[0]; ++i)
        for (ssize_t j = 0; j < buf.shape[1]; ++j)
            mat(i, j) = ptr[i * buf.shape[1] + j];

    return mat;
}

arma::vec numpy_to_arma_vec(const py::array_t<double>& array) {
    py::buffer_info buf = array.request();
    if (buf.ndim != 1)
        throw std::runtime_error("NumPy array must be 1D for arma::vec");

    arma::vec vec(buf.shape[0]);
    double* ptr = static_cast<double*>(buf.ptr);
    for (ssize_t i = 0; i < buf.shape[0]; ++i)
        vec(i) = ptr[i];

    return vec;
}


PYBIND11_MODULE(linregpy, m) {
    m.doc() = "Python bindings for LinearRegression C++ library (Armadillo-based)";

    // ---------------------------
    // Base class: LinearRegression
    // ---------------------------
    py::class_<LinearRegression, std::shared_ptr<LinearRegression>>(m, "LinearRegression")
        .def("fit", [](LinearRegression& self,
                       const py::array_t<double>& X,
                       const py::array_t<double>& y) {
            self.fit(numpy_to_arma_mat(X), numpy_to_arma_vec(y));
        })


        .def("predictSingleValue", [](const LinearRegression& self,
                                      const py::array_t<double>& X_pred,
                                      py::object params_obj) {
            arma::vec X = numpy_to_arma_vec(X_pred);
            arma::vec p = params_obj.is_none()
                            ? arma::vec()
                            : numpy_to_arma_vec(params_obj.cast<py::array_t<double>>());
            return self.predictSingleValue(X, p);
        }, py::arg("X_pred"), py::arg("params") = py::none())

        .def("predict", [](const LinearRegression& self,
                           const py::array_t<double>& X_pred,
                           py::object params_obj) {
            arma::mat X = numpy_to_arma_mat(X_pred);
            arma::vec p = params_obj.is_none()
                            ? arma::vec()
                            : numpy_to_arma_vec(params_obj.cast<py::array_t<double>>());
            return arma_vec_to_numpy(self.predict(X, p));
        }, py::arg("X_pred"), py::arg("params") = py::none())

        .def("getCoeffs", [](const LinearRegression& self) {
            return arma_vec_to_numpy(self.getCoeffs());
        })

        .def("kFoldCrossValidation", [](const LinearRegression& self,
                                        const py::array_t<double>& X,
                                        const py::array_t<double>& y,
                                        size_t k) {
            auto results = self.kFoldCrossValidation(
                numpy_to_arma_mat(X),
                numpy_to_arma_vec(y),
                k
            );
            return py::cast(results); // std::vector<double> → list
        }, py::arg("X"), py::arg("y"), py::arg("k") = 5)

        .def("RMSEReport", [](const LinearRegression& self,
                              const py::array_t<double>& X_test,
                              const py::array_t<double>& y_test) {
            self.RMSEReport(numpy_to_arma_mat(X_test), numpy_to_arma_vec(y_test));
        }, py::arg("X_test"), py::arg("y_test"));

    // ---------------------------
    // Derived: NormalEquation
    // ---------------------------
    py::class_<NormalEquation, LinearRegression, std::shared_ptr<NormalEquation>>(m, "NormalEquation")
        .def(py::init<>())
        .def("fit", [](NormalEquation& self,
                       const py::array_t<double>& X,
                       const py::array_t<double>& y) {
            self.fit(numpy_to_arma_mat(X), numpy_to_arma_vec(y));
        }, py::arg("X_train"), py::arg("y_train"));


    // ---------------------------
    // Derived: BatchGradientDescent
    // ---------------------------
    py::class_<BatchGradientDescent, LinearRegression, std::shared_ptr<BatchGradientDescent>>(m, "BatchGradientDescent")
        .def(py::init<double, size_t>(), py::arg("eta"), py::arg("n") = 1000)
        .def("fit", [](BatchGradientDescent& self,
                       const py::array_t<double>& X,
                       const py::array_t<double>& y) {
            self.fit(numpy_to_arma_mat(X), numpy_to_arma_vec(y));
        }, py::arg("X_train"), py::arg("y_train"));
}
